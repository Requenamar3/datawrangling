{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 1.05 - Guided Exercise**\n",
        "### Outliers - Quantity Investigation"
      ],
      "metadata": {
        "id": "PHolGx4JugWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "mTfyFKxG7dU5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVROL5U5Qn0T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "import certifi\n",
        "from sklearn.datasets import fetch_openml"
      ],
      "metadata": {
        "id": "Dq4a_UAeSVT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Data"
      ],
      "metadata": {
        "id": "ouVZ039d7gxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/fenago/datawrangling/main/miami-housing.csv')\n",
        "df.sample(5)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "P00Y6YbaSkxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Structure Investigation**\n",
        "\n"
      ],
      "metadata": {
        "id": "GMkDeWtgoRM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show size of the dataset\n",
        "df.shape\n"
      ],
      "metadata": {
        "id": "Qlj3lv8poT8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count how many times each data type is present in the dataset\n",
        "pd.value_counts(df.dtypes)"
      ],
      "metadata": {
        "id": "qXAirAjsolY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structure of numerical features\n"
      ],
      "metadata": {
        "id": "cZwoBLrJusia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For each numerical feature compute number of unique entries\n",
        "unique_values = df.select_dtypes(include='number').nunique().sort_values()\n",
        "plt.figure(figsize=(15, 4))\n",
        "sns.set_style('whitegrid')\n"
      ],
      "metadata": {
        "id": "VeBD5qY3umbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "g = sns.barplot(x=unique_values.index, y=unique_values, palette='inferno')\n",
        "g.set_yscale(\"log\")\n",
        "g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
        "g.set_title('Unique values per frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CT7pbHBVuyfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Conclusion of structure investigation\n"
      ],
      "metadata": {
        "id": "RUDrUb-3wgLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() \n",
        "df.describe()"
      ],
      "metadata": {
        "id": "xPk4-A_3wT2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quality Investigation\n",
        "Duplicates, missing values and unwanted entries or errors will be seen\n"
      ],
      "metadata": {
        "id": "smJl2VAwwrik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check number of duplicates while ignoring the index feature\n",
        "n_duplicates = df.drop(labels=['PARCELNO'], axis=1).duplicated().sum()\n",
        "\n",
        "print(f\"You seem to have {n_duplicates} duplicates in your database.\")"
      ],
      "metadata": {
        "id": "0GPan1b8wrB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Extract column names of all features, except 'PARCELNO'\n",
        "columns_to_consider = df.drop(labels=['PARCELNO'], axis=1).columns\n",
        "\n",
        "# Drop duplicates based on 'columns_to_consider'\n",
        "df.drop_duplicates(subset=columns_to_consider, inplace=True)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "BwUEHz_7w-lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 4))\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "g = sns.barplot(x=unique_values.index, y=unique_values, palette='inferno')\n",
        "g.set_yscale(\"log\")\n",
        "g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
        "g.set_title('Unique values per frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "drjvzFk2Z6pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "g = sns.heatmap(df_X.isnull(), cbar=False, cmap='viridis')\n",
        "g.set_xlabel('Column Number')\n",
        "g.set_ylabel('Sample Number')"
      ],
      "metadata": {
        "id": "7gDl1P-8aAYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install missingno\n",
        "import missingno as msno\n",
        "msno.matrix(df, labels=True, sort='descending', color=(0.27, 0.52, 1.0));\n",
        "# g = msno.bar(df_X, labels=True, color=\"dodgerblue\", sort=\"ascending\", figsize=(10,5), fontsize=12)\n",
        "# g.set_xticklabels(g.get_xticklabels(),rotation=90);"
      ],
      "metadata": {
        "id": "tEWENz27aN12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = df.dropna(thresh=df.shape[1] * 0.80, axis=0).reset_index(drop=True)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "pDZvrZU4aTPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Per Feature\n",
        "Let's look at the number of missing values per feature. \n"
      ],
      "metadata": {
        "id": "C5vL2iqsag4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().mean().sort_values().plot(\n",
        "    kind=\"bar\", figsize=(15, 4),\n",
        "    title=\"Percentage of missing values per feature\",\n",
        "    ylabel=\"Ratio of missing values per feature\");\n"
      ],
      "metadata": {
        "id": "x3bU5nRJaexw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = df.dropna(thresh=df.shape[0] * 0.85, axis=1)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "vaoGGrwXaufH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Numerical Features\n",
        " Pandas' .plot() function will be used here:"
      ],
      "metadata": {
        "id": "zuUp8rpWntVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot(lw=0, marker=\".\", subplots=True, layout=(-1, 4),\n",
        "          figsize=(15, 30), markersize=1);"
      ],
      "metadata": {
        "id": "HQDJcZ65ntCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Non-numerical features"
      ],
      "metadata": {
        "id": "6niWTg4Mn8XY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display non-numerical features\n",
        "df.select_dtypes(exclude=\"number\").head()\n"
      ],
      "metadata": {
        "id": "HYi6sZaOn7cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Content Investigation**"
      ],
      "metadata": {
        "id": "zW_goKgS8GL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Distribution"
      ],
      "metadata": {
        "id": "Zpm4kBPy95_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots the histogram for each numerical feature in a separate subplot\n",
        "df.hist(bins=25, figsize=(15, 25), layout=(-1, 5), edgecolor=\"black\")\n",
        "plt.tight_layout();"
      ],
      "metadata": {
        "id": "-w39jS0hot_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collects for each feature the most frequent entry\n",
        "# most_frequent_entry = df_X.mode()\n",
        "\n",
        "# Checks for each entry if it contains the most frequent entry\n",
        "# df_freq = df_X.eq(most_frequent_entry.values)\n",
        "\n",
        "# Computes the mean of the 'is_most_frequent' occurrence\n",
        "# df_freq = df_freq.mean().sort_values(ascending=False)\n",
        "\n",
        "# Show the 5 top features with the highest ratio of singular value content\n",
        "# display(df_freq.head())\n",
        "\n",
        "# Visualize the 'df_freq' table\n",
        "# df_freq.plot.bar(figsize=(15, 4));"
      ],
      "metadata": {
        "id": "8Zp_PxiQo4ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Patterns"
      ],
      "metadata": {
        "id": "Mqb0dvLn-MD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Continuous Features"
      ],
      "metadata": {
        "id": "HaTCc2TY-gDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creates mask to identify numerical features with more or less than 25 unique features\n",
        "cols_continuous = df.select_dtypes(include=\"number\").nunique() >= 25\n",
        "\n",
        "# Create a new dataframe which only contains the continuous features\n",
        "df_continuous = df[cols_continuous[cols_continuous].index]\n",
        "df_continuous.shape\n",
        "\n",
        "sns.pairplot(df_continuous, height=1.5, plot_kws={\"s\": 2, \"alpha\": 0.2});"
      ],
      "metadata": {
        "id": "c3NrP5rkpO0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataframe which doesn't contain the numerical continuous features\n",
        "df_discrete = df[cols_continuous[~cols_continuous].index]\n",
        "df_discrete.shape"
      ],
      "metadata": {
        "id": "m7Wwniz5pvyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Establish number of columns and rows needed to plot all features\n",
        "# n_cols = 5\n",
        "# n_elements = len(df_discrete.columns)\n",
        "# n_rows = np.ceil(n_elements / n_cols).astype(\"int\")\n",
        "\n",
        "# Specify y_value to spread data (ideally a continuous feature)\n",
        "# y_value = df_X[\"SALE_PRC\"]\n",
        "\n",
        "# Create figure object with as many rows and columns as needed\n",
        "# fig, axes = plt.subplots(ncols=n_cols, nrows=n_rows, figsize=(15, n_rows * 2.5))\n",
        "\n",
        "# Loop through features and put each subplot on a matplotlib axis object\n",
        "# for col, ax in zip(df_discrete.columns, axes.ravel()):\n",
        "#     sns.stripplot(data=df_X, x=col, y=y_value, ax=ax, palette=\"tab10\", size=1, alpha=0.5)\n",
        "# plt.tight_layout();\n"
      ],
      "metadata": {
        "id": "jY9truUTpvpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Relationships"
      ],
      "metadata": {
        "id": "vnjudlQy-teu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate but remember to consider multicollinearity\n",
        "\n",
        "# Computes feature correlation\n",
        "df_corr = df.corr(method=\"pearson\")\n",
        "\n",
        "# Create labels for the correlation matrix\n",
        "labels = np.where(np.abs(df_corr)>0.75, \"S\",\n",
        "                  np.where(np.abs(df_corr)>0.5, \"M\",\n",
        "                           np.where(np.abs(df_corr)>0.25, \"W\", \"\")))\n",
        "\n",
        "# Plot correlation matrix\n",
        "plt.figure(figsize=(15, 15))\n",
        "sns.heatmap(df_corr, mask=np.eye(len(df_corr)), square=True,\n",
        "            center=0, annot=labels, fmt='', linewidths=.5,\n",
        "            cmap=\"vlag\", cbar_kws={\"shrink\": 0.8});"
      ],
      "metadata": {
        "id": "bEWxSAeUxK9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Creates a mask to remove the diagonal and the upper triangle.\n",
        "lower_triangle_mask = np.tril(np.ones(df_corr.shape), k=-1).astype(\"bool\")\n",
        "\n",
        "#  Stack all correlations, after applying the mask\n",
        "df_corr_stacked = df_corr.where(lower_triangle_mask).stack().sort_values()\n",
        "\n",
        "#  Showing the lowest and highest correlations in the correlation matrix\n",
        "display(df_corr_stacked)"
      ],
      "metadata": {
        "id": "UKquQNS7xblx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Outliers**"
      ],
      "metadata": {
        "id": "v6QcVn1npw3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = df_X.quantile(0.25)\n",
        "Q3 = df_X.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "print(IQR)\n",
        "# print(df_X < (Q1 - 1.5 * IQR)) |(df_X > (Q3 + 1.5 * IQR))"
      ],
      "metadata": {
        "id": "milKz4HYpweK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_out = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "df_out.shape"
      ],
      "metadata": {
        "id": "j4TwCkZZp7qT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}