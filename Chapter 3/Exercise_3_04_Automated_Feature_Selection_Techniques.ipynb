{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 3.04: Guided exercise**\n",
        "### Automated Feature Selection Techniques"
      ],
      "metadata": {
        "id": "0tDvGojc6Gp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "     Follow the steps mentioned below corresponding to each code cell to perform the tasks:\n"
      ],
      "metadata": {
        "id": "3jYX7cdFIN4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "     Start with Loading the Dataset from GitHub."
      ],
      "metadata": {
        "id": "E8dJKsxpKY-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "     Then look for the null values in dataset. Remove them if they exist.\n",
        "Follow these steps to perform the initial tasks on the dataset:"
      ],
      "metadata": {
        "id": "KR9YvbG1Klp4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Dataset"
      ],
      "metadata": {
        "id": "K0B_7iy7KrOD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ik7-qpuu6Fzb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = 'https://raw.githubusercontent.com/fenago/datawrangling/main/miami-housing.csv'\n",
        "df = pd.read_csv(data)\n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Printing the shape of dataset"
      ],
      "metadata": {
        "id": "nDnSM3KLLHpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "_Ov89MP5-p4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Printing the names of features/columns"
      ],
      "metadata": {
        "id": "uTE-4NfGLNdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "nUtbddmO-ZGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print the total null values per column"
      ],
      "metadata": {
        "id": "5uxGzRoZLd57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# total null values per column\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "Xl_ha2jO-rO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uncorrelated Features:\n",
        "Features will be checked in such a way that if target variable and that feature is uncorrelated, just drop it:"
      ],
      "metadata": {
        "id": "K0KvuDV1MULn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop uncorrelated numeric features withthreshold <0.2"
      ],
      "metadata": {
        "id": "4bS1C4dvMrdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the correlation between target and features"
      ],
      "metadata": {
        "id": "BxbF9c1NMzsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation between target and features\n",
        "df_isnull = df.fillna(0)\n"
      ],
      "metadata": {
        "id": "0D4selbs-twd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop uncorrelated numeric features (threshold <0.2)\n",
        "corr = abs(df.corr().loc['SALE_PRC'])\n",
        "corr = corr[corr<0.3]\n",
        "cols_to_drop = corr.index.to_list()\n",
        "df = df.drop(cols_to_drop, axis=1)"
      ],
      "metadata": {
        "id": "aVIXctfV-wKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation between target and features\n",
        "(df.corr().loc['SALE_PRC']\n",
        " .plot(kind='barh', figsize=(4,10)))"
      ],
      "metadata": {
        "id": "R8KpxyqDmG8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Low variance features**\n",
        "Check the feature with low variance in our dataset. Drop it after that"
      ],
      "metadata": {
        "id": "QV-twZKANNaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "# variance of numeric features\n",
        "(df.select_dtypes(include=np.number).var().astype('str'))"
      ],
      "metadata": {
        "id": "5n6-CDlh-zeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Lowest is of Structure Quality."
      ],
      "metadata": {
        "id": "FOsppCfhNt7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop the feature: structure_quality"
      ],
      "metadata": {
        "id": "mWtb68ufNyTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['structure_quality'].describe()"
      ],
      "metadata": {
        "id": "m9yjZ29N-1D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Multi-collinearity**\n",
        "Check for the  feature that is more related with a target variable, and then delete it. "
      ],
      "metadata": {
        "id": "-lIhQftVN6ho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be seen that the “TOT_LVG_AREA” and “LND_SQFOOT” are more correlated with SALE_PRC."
      ],
      "metadata": {
        "id": "PMPbmvZyPAfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So you can eliminate one of them and let some other feature predict the target variable."
      ],
      "metadata": {
        "id": "HiLqwwxZPDr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "sns.set(rc={'figure.figsize':(16,10)})\n",
        "sns.heatmap(df.corr(),\n",
        "            annot=True,\n",
        "            linewidths=.5,\n",
        "            center=0,\n",
        "            cbar=False,\n",
        "            cmap=\"PiYG\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kjwP2MTW-21I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop correlated features"
      ],
      "metadata": {
        "id": "USHBak4UPirD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop correlated features\n",
        "df = df.drop(['SPEC_FEAT_VAL', 'SUBCNTR_DI', 'structure_quality'], axis=1)"
      ],
      "metadata": {
        "id": "8_bM9ewg-4m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numerical Features:"
      ],
      "metadata": {
        "id": "q3AjUSegPlLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_num = df[['LND_SQFOOT', 'TOT_LVG_AREA']]\n",
        "df_num.sample(5)"
      ],
      "metadata": {
        "id": "_RH6ikg8-6W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a crosstab/contingency table of numerical features in each column"
      ],
      "metadata": {
        "id": "O0Kb2w0nPsVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crosstab = pd.crosstab(df_num['LND_SQFOOT'], df_num['TOT_LVG_AREA'])\n",
        "crosstab"
      ],
      "metadata": {
        "id": "SVoii5dw-8Qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Chi-squared test on the contingency table that will tell us whether the two features are independent"
      ],
      "metadata": {
        "id": "bJ-XzplEQOIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "chi2_contingency(crosstab)"
      ],
      "metadata": {
        "id": "jG9_TKci-9zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop columns with missing values\n",
        "df = df.dropna()\n",
        "from sklearn.model_selection import train_test_split\n",
        "# get dummies for categorical features\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "# X features\n",
        "X = df.drop('SALE_PRC', axis=1)\n",
        "# y target\n",
        "y = df['SALE_PRC']\n",
        "# split data into training and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "# convert back to dataframe\n",
        "X_train = pd.DataFrame(X_train, columns = X.columns.to_list())\n",
        "X_test = pd.DataFrame(X_test, columns = X.columns.to_list())\n",
        "# instantiate model\n",
        "model = LinearRegression()\n",
        "# fit\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "0X-1IRbd_C5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feature Coefficients**\n",
        "As it is a regression model, we will be using regression coefficients, which will show the relative contributions of features in the model "
      ],
      "metadata": {
        "id": "0S-bznEJQVn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature coefficients\n",
        "coeffs = model.coef_\n",
        "# visualizing coefficients\n",
        "index = X_train.columns.tolist()\n",
        "(pd.DataFrame(coeffs, index = index, columns = ['coeff']).sort_values(by = 'coeff')\n",
        " .plot(kind='barh', figsize=(4,10)))"
      ],
      "metadata": {
        "id": "5V4cNisd_EuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter variables near zero coefficient value\n",
        "temp = pd.DataFrame(coeffs, index = index, columns = ['coeff']).sort_values(by = 'coeff')\n",
        "temp = temp[(temp['coeff']>1) | (temp['coeff']< -1)]\n",
        "# drop those features\n",
        "cols_coeff = temp.index.to_list()\n",
        "X_train = X_train[cols_coeff]\n",
        "X_test = X_test[cols_coeff]"
      ],
      "metadata": {
        "id": "dUx8XqWb_GYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **P-value**"
      ],
      "metadata": {
        "id": "KWoDoBouQtKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2qjVgQVyQw31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "ols = sm.OLS(y, X).fit()\n",
        "print(ols.summary())"
      ],
      "metadata": {
        "id": "qp_qyqQy_IJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Variance Inflation Factor**\n",
        "Check VIF for multicollinearity"
      ],
      "metadata": {
        "id": "if4UiL43RFzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keep all the features that have VIF below 10"
      ],
      "metadata": {
        "id": "46n2oqiXRZNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "# calculate VIF\n",
        "vif = pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns)\n",
        "# display VIFs in a table\n",
        "index = X_train.columns.tolist()\n",
        "vif_df = pd.DataFrame(vif, index = index, columns = ['vif']).sort_values(by = 'vif', ascending=False)\n",
        "vif_df[vif_df['vif']<10]"
      ],
      "metadata": {
        "id": "X0Vs74q9_LOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feature Importance:**\n"
      ],
      "metadata": {
        "id": "afdoPnt2SMRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing a model through Decision trees"
      ],
      "metadata": {
        "id": "JujsVvu4SY7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Then plotting the features importance"
      ],
      "metadata": {
        "id": "ooIZ5w2ESfI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 20)\n",
        "from sklearn.tree import DecisionTreeClassifier #Decision Tree\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "# get importance\n",
        "importance = model.feature_importances_\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "    \n",
        "# plot feature importance\n",
        "plt.bar([x for x in range(len(importance))], importance)\n",
        "plt.axhline(y=0.05, color='r', linestyle='-')\n",
        "plt.show()\n",
        "#use only high important features to feed into a model\n",
        "for i,v in enumerate(importance):\n",
        "    if v >= 0.05:\n",
        "        print('Feature: %0d, Score: %.5f' % (i,v))\n"
      ],
      "metadata": {
        "id": "Mf8esvje_NNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check out feature importance"
      ],
      "metadata": {
        "id": "2_CzQjmeSqq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  feature importance\n",
        "importances = model.feature_importances_\n",
        "# visualization\n",
        "cols = X.columns\n",
        "(pd.DataFrame(importances, cols, columns = ['importance'])\n",
        " .sort_values(by='importance', ascending=True)\n",
        " .plot(kind='barh', figsize=(4,10)))"
      ],
      "metadata": {
        "id": "wHcm1xE7_Oya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Automated Feature Selection Techniques**"
      ],
      "metadata": {
        "id": "LYQHoqmhXQK2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing Chi-square based technqiue and Regularization"
      ],
      "metadata": {
        "id": "WCc_oiNvXXJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import modules"
      ],
      "metadata": {
        "id": "-UUZEFedXjOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. select K best features"
      ],
      "metadata": {
        "id": "jpPVAQIzXlig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Keep 75% top features"
      ],
      "metadata": {
        "id": "QXuYGnYsXrwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import modules\n",
        "from sklearn.feature_selection import (SelectKBest, chi2, SelectPercentile, SelectFromModel, SequentialFeatureSelector, SequentialFeatureSelector)"
      ],
      "metadata": {
        "id": "MWenRsTR_TUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chi-Square**"
      ],
      "metadata": {
        "id": "0ORucZkuX2vM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select K best features\n",
        "X_best = SelectKBest(chi2, k='all').fit_transform(X,y)\n",
        "# number of best features\n",
        "X_best.shape[1]"
      ],
      "metadata": {
        "id": "cTxGKTSQ_VBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keep 75% top features \n",
        "X_top = SelectPercentile(chi2, percentile = 75).fit_transform(X,y)\n",
        "# number of best features\n",
        "X_top.shape[1]"
      ],
      "metadata": {
        "id": "6IMXH8RC_W_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Regularization**"
      ],
      "metadata": {
        "id": "kxFSyqVwXxCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implement algorithm\n",
        "from sklearn.svm import LinearSVC\n",
        "model = LinearSVC(penalty= 'l1', C = 0.002, dual=False)\n",
        "model.fit(X,y)\n",
        "# select features using the meta transformer\n",
        "selector = SelectFromModel(estimator = model, prefit=True)\n",
        "X_new = selector.transform(X)\n",
        "X_new.shape[1]\n",
        "\n",
        "# names of selected features\n",
        "feature_names = np.array(X.columns)\n",
        "feature_names[selector.get_support()]\n"
      ],
      "metadata": {
        "id": "z2d97dfe_ZDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
